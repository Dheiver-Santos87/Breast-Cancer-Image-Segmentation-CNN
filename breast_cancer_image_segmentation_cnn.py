# -*- coding: utf-8 -*-
"""breast-cancer-image-segmentation-cnn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DkOhOaK2a8WfU9OrGSt7FVMkiH2HOpBu

# Breast Ultrasound Image Classification Using CNN

![case-B.jpg](attachment:0a0f776a-ef2a-4395-9275-a96f998d8c28.jpg)

#### In This notebook we'll try to classify different breast ultrasound using convolutional neural network with tensorflow.

# What is CNN ?

#### CNN is a powerful algorithm for image processing. These algorithms are currently the best algorithms we have for the automated processing of images. Many companies use these algorithms to do things like identifying the objects in an image.

# Three Layers of CNN

#### Convolutional Neural Networks specialized for applications in image & video recognition. CNN is mainly used in image analysis tasks like Image recognition, Object detection & Segmentation.

#### There are three types of layers in Convolutional Neural Networks:

![1_uAeANQIOQPqWZnnuH-VEyw.jpeg](attachment:eaa7eb02-03c9-4a52-8516-86ecd6e326e0.jpeg)

**1) Convolutional Layer:**

**In a typical neural network each input neuron is connected to the next hidden layer. In CNN, only a small region of the input layer neurons connect to the neuron hidden layer.**

**2) Pooling Layer:**

**The pooling layer is used to reduce the dimensionality of the feature map. There will be multiple activation & pooling layers inside the hidden layer of the CNN.**

**3) Fully-Connected layer:**

**Fully Connected Layers form the last few layers in the network. The input to the fully connected layer is the output from the final Pooling or Convolutional Layer, which is flattened and then fed into the fully connected layer.**

#### Let's Start ⌨️

# Data İmportation

**İmporting basic libraries**
"""

import tensorflow as tf
import pandas as pd 
from PIL import Image
import os
import numpy as np
import matplotlib.pyplot as plt 
import os 
import pathlib 
import random

"""**Defining the path**"""

path = './Dataset_BUSI_with_GT/'
data_dir = pathlib.Path(path)

"""**Getting class names**"""

class_names = np.array(sorted([item.name for item in data_dir.glob("*")]))
class_names

"""**Define paths and image count**"""

benignPath = os.path.join(data_dir,'bening')
malignantPath = os.path.join(data_dir,'malignant')
normalPath = os.path.join(data_dir,'normal')

"""**İmage count**"""

imageCount = len(list(data_dir.glob('*/*.png')))
imageCount

"""# Make Plotting of Random İmages"""

plt.figure(figsize=(15,15))

for i in range(25):
    plt.subplot(5,5,i+1)
    random_class = random.choice(class_names)
    img = plt.imread(random.choice(list(data_dir.glob(random_class+"/*.png"))))
    plt.xticks([])
    plt.yticks([])
    plt.title(random_class)
    plt.imshow(img)

"""**Check the image formats**"""

from pathlib import Path
import imghdr

data_dir = './Dataset_BUSI_with_GT/'
image_extensions = [".png", ".jpg"]  # add there all your images file extensions

img_type_accepted_by_tf = ["bmp", "gif", "jpeg", "png"]
for filepath in Path(data_dir).rglob("*"):
    if filepath.suffix.lower() in image_extensions:
        img_type = imghdr.what(filepath)
        if img_type is None:
            print(f"{filepath} is not an image")
        elif img_type not in img_type_accepted_by_tf:
            print(f"{filepath} is a {img_type}, not accepted by TensorFlow")

"""# Build the CNN"""

batch_size = 32
img_height = 224
img_width = 224

"""**Separating data sets**"""

from tensorflow.keras.utils import image_dataset_from_directory

train_data = image_dataset_from_directory(
                  data_dir,
                  validation_split=0.2,
                  subset="training",
                  seed=123,
                  image_size=(img_height, img_width),
                  batch_size=batch_size)


val_data = image_dataset_from_directory(data_dir,
                                        validation_split=0.2,
                                        subset="validation",
                                        seed=123,
                                        image_size=(img_height,img_width),
                                        batch_size=batch_size)

"""# Define the Model

#### The model have 3 blocks where in each block we have one convolutional layer and a max pooling to understand CNN you can follow this link which provide a good understanding of the subject https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53

**Roadmap**

##### We rescale images add a Dropout to avoid the overfitting as we have 4 class the last layer contain the number of class and we have softmax as activation,it will give us a pourcentage of each class and we'll choice the maximum pourcentage as the class
"""

from tensorflow.keras import layers 
model = tf.keras.Sequential([
  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),
    
  layers.Conv2D(16, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
    
  layers.Conv2D(32, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
    
  layers.Conv2D(64, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
    
  layers.Dropout(0.5),
  layers.Flatten(),
  layers.Dense(128, activation='relu'),
  layers.Dense(3,activation="softmax")
])

"""# Compile the Model"""

model.compile(optimizer="Adam",
            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
            metrics=["accuracy"])

"""**Use GPU to fit the model else it will take much more time**"""

epochs = 15
history = model.fit(train_data,
                    epochs=epochs,
                    validation_data=val_data, 
                    batch_size=batch_size)

"""**Keys**"""

history.history.keys()

"""# Accuracy vs Lost"""

acc = history.history['accuracy']
val_acc =  history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(epochs)

plt.figure(figsize=(8,8))
plt.subplot(1,2,1)
plt.plot(epochs_range,acc,label='Accuracy')
plt.plot(epochs_range,val_acc,label="Validation Accuracy")
plt.legend()

plt.subplot(1,2,2)
plt.plot(epochs_range,loss,label='Loss')
plt.plot(epochs_range,val_loss,label="Validation Loss")
plt.legend()
plt.show()

"""**Evaluating - İt return the lost and accuracy**"""

model.evaluate(val_data)

"""**Model summary**"""

model.summary()

"""# Predictions"""

plt.figure(figsize=(15, 15))
class_names = val_data.class_names
result = ' | False'
for images, labels in val_data.take(1):
    for i in range(25):
        
        ax = plt.subplot(5, 5, i + 1)
        img = images[i].numpy().astype("uint8")
        img = tf.expand_dims(img, axis=0)
        
        predictions = model.predict(img)
        predicted_class = np.argmax(predictions)
        if class_names[predicted_class] == class_names[labels[i]]:
            result = ' | TRUE'
            
        plt.imshow(images[i].numpy().astype("uint8"))
        plt.title(class_names[predicted_class]+result  )
        plt.axis("off")

model.save('my_model_new.h5')  # creates a HDF5 file 'my_model.h5'

"""# THANKS FOR REVİEWİNG !!!

## your Upvotes would be highly appreciated
"""